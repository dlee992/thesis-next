\section{实验设计和设置}

\input{table/table1.tex}

\subsection{基准测试集} 

为了便于\wa 和它的前身\cu 的比较，我们选择了 \cu 采用的从EUSES语料库中采样的测试集，作为我们的实验基准测试集。如表~\ref{table1}所示，该测试集包含70个电子表格和291个工作表。这291个工作表包含189,027个单元格，其中包含26,716个公式单元格。出于实验评估的目的，该测试集包含人工标注的数据(标记方法详见~\cite{cheung2016custodes})，其中包含1,610个单元格类和1,974个有缺陷的单元格(丢失公式或含有不一致的公式)。

\subsection{测试技术} 

在实验中，\wa 将和五个之前提到的电子表格缺陷检测技术进行对比，即\uc，\di，\am，\ca 和 \cu。我们从它们各自的原作者那里获取了对应的可执行工具或源码。主要在缺陷检测的有效性方面进行比较。对于\ca，我们额外比较了它们的单元格聚类的有效性。

为了评估的三个有效性精化的独立性(研究问题3)，我们采用不同的配置来测试各自的实验效果，三种配置依次分别标记为\wasc (带有单单元格的有效性精化)，\wamc (带有多单元格的有效性精化)，\wawc (带有整个类的有效性精化)。最后，带有全部三种精化的配置被称为\wa-full，或简记为\wa。

\subsection{评价指标} 

针对缺陷检测的有效性，我们首先统计每个技术报告的缺陷数量，以及其中的真阳性(TP)，假阳性(FP)和假阴性(FN)数量。基于此，我们进一步根据如下三组公式计算精度$precision_d$，召回率$recall_d$和$F\text{-}measure_d$值，来衡量电子表格缺陷检测上各技术的有效性。

\begin{gather*}
    precision_d=\frac{TP}{TP + FP}\qquad recall_d = \frac{TP}{TP + FN}\\
    f\text{-}measure_d = \frac{2 \times precision_d \times recall_d}{precision_d + recall_d}
\end{gather*}

针对电子表格缺陷的有效性(适用于\wa 和\cu )，我们采用和\cu 类似的方式来统计真阳性(TP)，假阳性(FP)和假阴性(FN)数量。类似地，我们也统计这两个技术在单元格聚类上的精度 $precision_c$，召回率 $recall_c$和\fmc 值。

\subsection{测试环境} 

所有实验在一台台式机上进行，配有 Intel$^\circledR$ Core\texttrademark\ i7-6700 CPU @3.41GHz 处理器和 64GB 内存。该机器上安装了微软Windows 10专业版操作系统和Oracle Java 8执行环境。

